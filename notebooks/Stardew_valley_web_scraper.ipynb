{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cecax27/DS-Stardew-Valley-Crops-Profit/blob/main/notebooks/Stardew_valley_web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraper on Stardew Valley wiki\n",
        "\n",
        "This notebook is to make web scraping on the Stardew Valley Wiki. We need to extract information about the crops, and the products that you can create with them.\n",
        "\n",
        "The url of the website is https://stardewvalleywiki.com. You can visit it to find a lot of information about the game.\n",
        "\n",
        "## Importing libraries"
      ],
      "metadata": {
        "id": "Hu9Ot_ZvI-TD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uyy0n8B6GoY0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaring constants"
      ],
      "metadata": {
        "id": "KoHjNG-UZt0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "home_url = 'https://stardewvalleywiki.com'\n",
        "crops_url = 'https://stardewvalleywiki.com/Crops'"
      ],
      "metadata": {
        "id": "2GHdP9dL7pT_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get crops urls list"
      ],
      "metadata": {
        "id": "A36oqlPxJRVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the request\n",
        "crops_page = requests.get(crops_url)\n",
        "\n",
        "# Pasing the HTML with BeatifulSoup\n",
        "crops_soup = BeautifulSoup(crops_page.text, 'lxml')\n",
        "\n",
        "#Finding the urls\n",
        "crops_names = crops_soup.find('div', attrs = {'class' : 'mw-parser-output'}).find_all('h3')[10:-1]\n",
        "\n",
        "#Making a links list\n",
        "crops_links_list = [home_url + crop_name.find_all('a')[1].get('href') for crop_name in crops_names]\n",
        "crops_names_list = [crop_name.get_text().strip() for crop_name in crops_names]\n",
        "\n",
        "print(f'{len(crops_links_list)} links founded')"
      ],
      "metadata": {
        "id": "E66wbo5eHOZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe76dfa-22e2-4dc9-e6e5-71448a620141"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 links founded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaring functions to extract data"
      ],
      "metadata": {
        "id": "SB4DRDonqz8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract information about the seed\n",
        "\n",
        "def get_seed_information(link) -> dict:\n",
        "\n",
        "  # Getting data to work\n",
        "  try:\n",
        "    s = requests.get(link)\n",
        "    raw_information = BeautifulSoup(s.text, 'lxml')\n",
        "  except Exception as e:\n",
        "    print('An error ocurred making the request:')\n",
        "    print(e)\n",
        "    print('\\n')\n",
        "    return dict()\n",
        "\n",
        "  # Dictionary to save the data\n",
        "  price_dict = dict()\n",
        "\n",
        "  # Finding data\n",
        "  for row in raw_information.find('table').find_all('tr'):\n",
        "\n",
        "    title = row.find('td').get_text().strip().replace(':', '').lower().replace(' ', '_')\n",
        "\n",
        "    if title == 'general_store':\n",
        "      try:\n",
        "        price_dict[title+'_price'] = int(row.find_all('td')[1].find_all('span')[1].get_text()[:-1])\n",
        "      except:\n",
        "        price_dict[title+'_price'] = np.nan\n",
        "\n",
        "    elif title == 'jojamart':\n",
        "      try:\n",
        "        price_dict[title+'_price'] = int(row.find_all('td')[1].find_all('span')[1].get_text()[:-1])\n",
        "      except:\n",
        "        price_dict[title+'_price'] = np.nan\n",
        "\n",
        "    elif title == 'oasis':\n",
        "      price_dict[title+'_price'] = int(row.find_all('td')[1].find_all('span')[1].get_text()[:-1])\n",
        "\n",
        "    elif title == 'traveling_cart':\n",
        "      try:\n",
        "        price_dict[title+'_price_min'] = int(row.find_all('td')[1].get_text().split('\"')[-1].split('g')[0].replace(',','').split('–')[0])\n",
        "        price_dict[title+'_price_max'] = int(row.find_all('td')[1].get_text().split('\"')[-1].split('g')[0].replace(',','').split('–')[1])\n",
        "      except:\n",
        "        price_dict[title+'_price_min'] = np.nan\n",
        "        price_dict[title+'_price_max'] = np.nan\n",
        "\n",
        "    elif title == 'night_market(winter_15)':\n",
        "      price_dict[title.split('(')[0]+'_price'] = int(row.find_all('td')[1].find_all('span')[1].get_text()[:-1])\n",
        "\n",
        "    elif title == 'other':\n",
        "      price_dict[row.find_all('td')[1].find('a').get_text().strip().lower().replace(' ', '_')+'_price'] = int(row.find_all('td')[1].find_all('span')[-1].get_text().split('g')[0])\n",
        "\n",
        "  return price_dict"
      ],
      "metadata": {
        "id": "KUphWuyLrqpo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "pprint(get_seed_information('https://stardewvalleywiki.com/Starfruit_Seeds'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcVb7KgVsOFp",
        "outputId": "4f737f28-616a-42c9-89d9-ebde7044eb06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'general_store_price': nan,\n",
            " 'jojamart_price': nan,\n",
            " 'oasis_price': 400,\n",
            " 'traveling_cart_price_max': 1000,\n",
            " 'traveling_cart_price_min': 600}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import S\n",
        "def get_crop_information(link) -> dict:\n",
        "\n",
        "  # Getting data to work\n",
        "  try:\n",
        "    request = requests.get(link)\n",
        "    s = BeautifulSoup(request.text, 'lxml')\n",
        "    raw_information = s.find('table').find_all('tr')\n",
        "  except Exception as e:\n",
        "    print('An error ocurred making the request:')\n",
        "    print(e)\n",
        "    print('\\n')\n",
        "    return dict()\n",
        "\n",
        "  # Constants\n",
        "  prices_sufix = ['regular', 'silver', 'gold', 'iridium']\n",
        "\n",
        "  # Dictionary to save the data\n",
        "  inf_dict = {\n",
        "      'name' : raw_information[0].get_text().strip(),\n",
        "      'description' : raw_information[2].get_text().strip()\n",
        "  }\n",
        "\n",
        "  # Finding data\n",
        "  for data in raw_information[4:]:\n",
        "\n",
        "    field = data.find('td').get_text().strip().lower().replace(' ', '_')\n",
        "\n",
        "    if '\\t' in field or ':' in field or '/' in field or field == '' or field[0].isdigit():\n",
        "      continue\n",
        "\n",
        "    if field == 'sell_price' or field == 'sell_prices':\n",
        "      try:\n",
        "        prices = data.find('table').find_all('td')\n",
        "        prices = list(map(lambda i: i.get_text().split('g')[0], prices))[1:]\n",
        "        prices = list(filter(lambda i: i != '', prices))\n",
        "        prices = list(map(lambda i: int(i.replace(',', '')), prices))\n",
        "        for index, price in enumerate(prices):\n",
        "          inf_dict[field+'_'+prices_sufix[index]] = price\n",
        "        continue\n",
        "      except Exception as e:\n",
        "        try:\n",
        "          index = raw_information.index(data) + 2\n",
        "          prices = raw_information[index].find('table').find_all('td')\n",
        "          prices = list(map(lambda i: i.get_text().split('g')[0].replace(',',''), prices))[1:]\n",
        "          prices = list(filter(lambda i: i != '', prices))\n",
        "          prices = list(map(lambda i: int(i), prices))\n",
        "          for index, price in enumerate(prices):\n",
        "            inf_dict[field+'_'+prices_sufix[index]] = price\n",
        "          continue\n",
        "        except Exception as e:\n",
        "          td = data.find_all('td')\n",
        "          if td:\n",
        "            span = td[-1].find_all('span')\n",
        "            if span:\n",
        "              price = int(span[-1].get_text().split('g')[0].strip())\n",
        "              for index in range(4):\n",
        "                inf_dict[field+'_'+prices_sufix[index]] = price\n",
        "              continue\n",
        "          print(f'An error ocurred extracting the data \"{field}\" from {link}:')\n",
        "          print(e)\n",
        "          print('\\n')\n",
        "        continue\n",
        "\n",
        "    if field == 'seed':\n",
        "      try:\n",
        "        seed_link = data.find_all('td')[1].find('a').get('href')\n",
        "        if seed_link:\n",
        "          url = home_url + seed_link\n",
        "          inf_dict.update(get_seed_information(url))\n",
        "      except Exception as e:\n",
        "        print(f'An error ocurred extracting the data \"{field}\" from {link}:')\n",
        "        print(e)\n",
        "        print('\\n')\n",
        "    try:\n",
        "      inf_dict[field] = data.find_all('td')[1].get_text().strip().replace(' • ', ',')\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  # Found if it regrowth or not\n",
        "  try:\n",
        "    table = s.find('table', attrs = {'class': 'wikitable roundedborder'})\n",
        "    row = table.find_all('tr')[2]\n",
        "    cell = row.find_all('td')[-1]\n",
        "    if 'Regrowth' in cell.get_text():\n",
        "      days = int(cell.get_text().split(' ')[1])\n",
        "      inf_dict['regrowth_time'] = days\n",
        "    else:\n",
        "      inf_dict['regrowth_time'] = np.nan\n",
        "  except:\n",
        "    inf_dict['regrowth_time'] = np.nan\n",
        "\n",
        "  return inf_dict"
      ],
      "metadata": {
        "id": "9H2Jf8TX-yz1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "pprint(get_crop_information('https://stardewvalleywiki.com/Green_Bean'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG5Mp31KxL3A",
        "outputId": "a057ff55-b2b5-470c-f9cd-2f90b38f2cf2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'base': 'Artisan (+40%)',\n",
            " 'description': 'A juicy little bean with a cool, crisp snap.',\n",
            " 'general_store_price': 60,\n",
            " 'growth_time': '10 days',\n",
            " 'jojamart_price': 75,\n",
            " 'name': 'Green Bean',\n",
            " 'night_market_price': 60,\n",
            " 'regrowth_time': 3,\n",
            " 'season': 'Spring',\n",
            " 'seed': 'Bean Starter',\n",
            " 'sell_prices_gold': 60,\n",
            " 'sell_prices_iridium': 80,\n",
            " 'sell_prices_regular': 40,\n",
            " 'sell_prices_silver': 50,\n",
            " 'traveling_cart_price_max': 1000,\n",
            " 'traveling_cart_price_min': 100,\n",
            " 'xp': '9 Farming XP'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting all the data\n",
        "\n",
        "I'll call my extract data functions with my links list. Also I'll save the data in a Pandas DataFrame."
      ],
      "metadata": {
        "id": "EmC2ozlX6Pot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting data\n",
        "df_data = [get_crop_information(link) for link in crops_links_list]\n",
        "\n",
        "# Extracting DataFrame columns\n",
        "columns = set()\n",
        "for sublist in [list(item.keys()) for item in df_data]:\n",
        "  for element in sublist:\n",
        "    columns.add(element)\n",
        "columns = list(columns)\n",
        "\n",
        "# Making the DataFrame\n",
        "df = pd.DataFrame(df_data, columns = columns)\n",
        "\n",
        "print(f'DataFrame created with {df.shape[0]} rows and {df.shape[1]} columns\\n')\n",
        "print('Columns:')\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "fWqJCKcv_r8c",
        "outputId": "48cdd2b0-7b45-483c-9644-71de19a1a804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame created with 43 rows and 26 columns\n",
            "\n",
            "Columns:\n",
            "growth_time                  object\n",
            "source                       object\n",
            "sell_prices_silver          float64\n",
            "seed                         object\n",
            "sell_prices_gold            float64\n",
            "description                  object\n",
            "general_store_price         float64\n",
            "night_market_price          float64\n",
            "sell_price_regular          float64\n",
            "egg_festival_price          float64\n",
            "sell_price_silver           float64\n",
            "traveling_cart_price_min    float64\n",
            "sell_prices_iridium         float64\n",
            "sell_price_iridium          float64\n",
            "artisan_sell_price           object\n",
            "sell_price_gold             float64\n",
            "sell_prices_regular         float64\n",
            "traveling_cart_price_max    float64\n",
            "regrowth_time               float64\n",
            "base                         object\n",
            "oasis_price                 float64\n",
            "xp                           object\n",
            "energy                       object\n",
            "season                       object\n",
            "jojamart_price              float64\n",
            "name                         object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'DataFrame created with {df.shape[0]} rows and {df.shape[1]} columns\\n')\n",
        "print('Columns:')\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpmq_GC4Mzxl",
        "outputId": "b7e735c2-f83e-401d-bf32-c7beb5f6f32e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame created with 43 rows and 26 columns\n",
            "\n",
            "Columns:\n",
            "growth_time                  object\n",
            "source                       object\n",
            "sell_prices_silver          float64\n",
            "seed                         object\n",
            "sell_prices_gold            float64\n",
            "description                  object\n",
            "general_store_price         float64\n",
            "night_market_price          float64\n",
            "sell_price_regular          float64\n",
            "egg_festival_price          float64\n",
            "sell_price_silver           float64\n",
            "traveling_cart_price_min    float64\n",
            "sell_prices_iridium         float64\n",
            "sell_price_iridium          float64\n",
            "artisan_sell_price           object\n",
            "sell_price_gold             float64\n",
            "sell_prices_regular         float64\n",
            "traveling_cart_price_max    float64\n",
            "regrowth_time               float64\n",
            "base                         object\n",
            "oasis_price                 float64\n",
            "xp                           object\n",
            "energy                       object\n",
            "season                       object\n",
            "jojamart_price              float64\n",
            "name                         object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I'll save my data in crops_raw_data.csv file."
      ],
      "metadata": {
        "id": "mOzO5BRKNika"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('crops_raw_data.csv')"
      ],
      "metadata": {
        "id": "hmPGksHoNtiT"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}